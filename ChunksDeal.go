package main

import (
	"bufio"
	"context"
	"errors"
	"fmt"
	"io"
	"math"
	"net/http"
	"strings"
	"sync"
	"time"
)

const (
	ExceedSize  = 100 * 1024 * 1024
	MaxAttempts = 3
	numWorkers  = 5
)

var ContinueOnClientClose = false

// ========== 1. Reader/Writerç»“æ„/å‡½æ•° ==========

type MonitorWriterChunks struct {
	ctx     context.Context
	Writer  *bufio.ReadWriter
	Monitor *ClientBytesRecorder
	LocalIP string
	Index   int
}

func (m *MonitorWriterChunks) Write(p []byte) (n int, err error) {
	select {
	case <-m.ctx.Done():
		return n, m.ctx.Err()
	default:
	}
	n, err = m.Writer.Write(p)
	if m.Index == 0 {
		counters := m.Monitor.GetOrCreate(m.LocalIP)
		counters.clientChunks0Bytes.Add(int64(n))
	} else if m.Index == 1 {
		counters := m.Monitor.GetOrCreate(m.LocalIP)
		counters.clientChunks1Bytes.Add(int64(n))
	}
	return n, err
}

type MonitorReaderChunks struct {
	ctx     context.Context
	Reader  io.Reader
	Monitor *ClientBytesRecorder
	LocalIP string
	Index   int
}

func (m *MonitorReaderChunks) Read(p []byte) (n int, err error) {
	select {
	case <-m.ctx.Done():
		return n, m.ctx.Err()
	default:
	}
	n, err = m.Reader.Read(p)
	if m.Index == 0 {
		counters := m.Monitor.GetOrCreate(m.LocalIP)
		counters.clientChunks0Bytes.Add(int64(n))
	} else if m.Index == 1 {
		counters := m.Monitor.GetOrCreate(m.LocalIP)
		counters.clientChunks1Bytes.Add(int64(n))
	}
	return n, err
}

// ========== 2. ä»»åŠ¡ç»“æ„ ==========

type ChunkTask struct {
	Index       int
	Start       int64
	End         int64
	Attempt     int
	ClientIP    string
	ClientIndex int
}
type ChunkBuffer struct {
	Index int64
	Data  []byte
}
type ChunkResult struct {
	Index int
	Data  []byte
	Err   error
}

// ========== 3. ä¸»å‡½æ•°éƒ¨åˆ† ==========

func (p *NetHTTPCho) ChunkCalculate(AllSize int64) ([]ChunkTask, error) {
	var chunkTasks []ChunkTask
	BestChunkSizeRecorder.mu.RLock()
	var BestChunkSizeContent = BestChunkSizeRecorder.content
	BestChunkSizeRecorder.mu.RUnlock()
	snapshot := p.current.Load()
	if len(snapshot.ChunksEntries) == 0 {
		return []ChunkTask{}, fmt.Errorf("chunks no probability available")
	}
	fmt.Printf("snapshotChunks: %v\n", snapshot.ChunksEntries)
	var TaskIndex = 0
	var AllStartPos int64 = 0.0
	var AllEndPos int64 = 0.0
	var AllSizePos = AllSize - 1
	var TaskSizePos int64
	for i, Entry := range snapshot.ChunksEntries {
		TaskSize := int64((Entry.ProbNum / snapshot.TotalChunks) * float64(AllSize))
		fmt.Printf("Entry Index%d: TaskSize%d\n", TaskIndex, TaskSize)
		if i == len(snapshot.ChunksEntries)-1 {
			TaskSizePos = AllSizePos
		} else {
			TaskSizePos = AllStartPos + TaskSize - 1
		}
		BestChunk := BestChunkSizeContent[Entry.IP]
		if BestChunk <= 0 {
			BestChunk = 5 * 1024 * 1024
		}
		for {
			if AllStartPos+2*BestChunk-1 <= TaskSizePos {
				AllEndPos += BestChunk - 1
				chunkTasks = append(chunkTasks, ChunkTask{Index: TaskIndex, End: AllEndPos, Start: AllStartPos, ClientIP: Entry.IP, ClientIndex: Entry.Index})
				AllStartPos = AllEndPos + 1
				AllEndPos = AllStartPos
				TaskIndex++
			} else {
				AllEndPos = TaskSizePos
				chunkTasks = append(chunkTasks, ChunkTask{Index: TaskIndex, End: AllEndPos, Start: AllStartPos, ClientIP: Entry.IP, ClientIndex: Entry.Index})
				AllStartPos = AllEndPos + 1
				AllEndPos = AllStartPos
				TaskIndex++
				break
			}
		}
	}
	return chunkTasks, nil
}
func ChunksDeal(bufrw *bufio.ReadWriter, r *http.Request, bag ChunkBag) error {
	// è§£æbagå†…éƒ¨å†…å®¹
	AllSize := bag.AllBytes
	TargetURL := bag.TargetURL // Maybe the r.url.string()

	// è®¡ç®—åˆ†å—
	TaskChunks, _ := NetCardCho.ChunkCalculate(AllSize)
	fmt.Printf("Total Chunks: %v\n", TaskChunks)
	lenChunks := len(TaskChunks)

	//ä¸å®¢æˆ·ç«¯è§£è€¦
	jobCtx, JobCancel := context.WithCancelCause(context.Background())
	defer JobCancel(nil)
	DirectCtx, DirectCancel := context.WithCancelCause(context.Background())
	defer DirectCancel(nil)

	//ç›‘å¬å®¢æˆ·ç«¯æ–­å¼€è®¯å·
	go func() {
		select {
		case <-r.Context().Done():
			if !ContinueOnClientClose {
				JobCancel(errors.New("client DisConnected"))
				DirectCancel(errors.New("client DisConnected"))
			}
		case <-jobCtx.Done():
			DirectCancel(errors.New("jobCtx Cancel"))
		}
		fmt.Printf("ctx canceled\n")
		return
	}()

	// æ„å»ºä»»åŠ¡å’Œç»“æœé€šé“
	taskCh := make(chan ChunkTask, lenChunks)
	resultCh := make(chan ChunkResult, 2*numWorkers)
	// æ„å»ºç›´è¿å½¢å¼Workeræ¡†æ¶
	TaskSizeDirect := AllSize / numWorkers
	TasksDirect, leftStart, err := ChunksDirectTaskGet(TaskChunks, TaskSizeDirect)
	if err != nil {
		return err
	}

	// æå‰æ³¨å…¥å¯¹åº”åé¢å‰©ä½™ä»»åŠ¡
	TasksLeft := TaskChunks[leftStart:]
	go func() {
		for _, task := range TasksLeft {
			taskCh <- task
		}
	}()

	var wg sync.WaitGroup
	wg.Add(numWorkers)

	go func() {
		DirectChunksWok(r.Context(), TasksDirect, bufrw, TargetURL, r.Header)
		wg.Done()
		DirectCancel(fmt.Errorf("finished all ChunksDirect"))
	}()

	for i := 1; i < numWorkers; i++ {
		go chunkWorker(jobCtx, i, TargetURL, taskCh, resultCh, r.Header, &wg)
	}
	// ç­‰å¾…æ‰€æœ‰ Worker å®Œæˆåå…³é—­ç»“æœé˜Ÿåˆ—
	go func() {
		wg.Wait()
		close(resultCh)
		close(taskCh)
		fmt.Println("âœ… æ‰€æœ‰ä¸‹è½½ä»»åŠ¡å®Œæˆ")
	}()

	// è¿›è¡Œæµå¼è¾“å‡ºè¿”å›å®¢æˆ·ç«¯
	// å‘é€å¾ªç¯
	next := leftStart
	pending := make(map[int][]byte)
	remaining := lenChunks - leftStart

	for {
		select {
		case <-jobCtx.Done():
			// ä»»åŠ¡è¢«å–æ¶ˆ
			err := context.Cause(jobCtx)
			if err != nil {
				fmt.Printf("âš ï¸ Job canceled: %v\n", err)
			}
			return nil
		case res, ok := <-resultCh:
			if !ok {
				// æ‰€æœ‰ worker é€€å‡ºï¼›è‹¥è¿˜æœ‰æœªå®Œæˆå—ï¼Œè¯´æ˜æ˜¯å¤±è´¥å–æ¶ˆ
				if remaining > 0 {
					fmt.Printf("âŒ ä»»åŠ¡æœªå®Œæˆä½†ç»“æœé€šé“å·²å…³é—­ï¼Œå‰©ä½™: %d\n", remaining)
				}
				return nil
			}
			if res.Err != nil {
				// å¤±è´¥çš„å—ï¼šå†³å®šæ˜¯å¦é‡è¯•
				if taskRetryable(res.Err) && res.Index >= 0 {
					// å¢åŠ é‡è¯•æ¬¡æ•°ï¼Œå›çŒä»»åŠ¡
					attempt := TaskChunks[res.Index].Attempt + 1
					TaskChunks[res.Index].Attempt = attempt
					if attempt <= MaxAttempts {
						backoff := time.Duration(math.Pow(2, float64(attempt-1))) * 200 * time.Millisecond
						time.AfterFunc(backoff, func() {
							select {
							case taskCh <- ChunkTask{Index: res.Index, Start: TaskChunks[res.Index].Start, End: TaskChunks[res.Index].End, Attempt: attempt}:
							case <-jobCtx.Done():
							}
						})
						fmt.Printf("ğŸ” é‡è¯• Chunk %dï¼ˆç¬¬ %d æ¬¡ï¼‰\n", res.Index, attempt)
						continue
					}
				}
				// ä¸å¯é‡è¯•æˆ–è¶…è¿‡æ¬¡æ•°ï¼šå–æ¶ˆå…¨å±€
				JobCancel(fmt.Errorf("fatal: chunk %d failed: %v", res.Index, res.Err))
				return nil
			}
			// æˆåŠŸï¼šç¼“å­˜å¹¶å°è¯•æŒ‰åºå†™å‡º
			pending[res.Index] = res.Data
		case <-DirectCtx.Done():
			// è¿›è¡Œå†™å…¥æ“ä½œ
			data, ok := pending[next]
			if !ok {
				continue
			}
			actualSize := len(data)
			chunkSize := fmt.Sprintf("%x\r\n", actualSize)
			if _, err := bufrw.WriteString(chunkSize); err != nil {
				fmt.Printf("err1: %+v\n", err)
				return nil
			}
			if _, err := bufrw.Write(data); err != nil {
				// å†™å›å¤±è´¥ï¼šå®¢æˆ·ç«¯å·²æ–­å¼€
				JobCancel(fmt.Errorf("write failed: %w", err))
				return nil
			}
			if _, err := bufrw.WriteString("\r\n"); err != nil {
				fmt.Printf("err3: %+v\n", err)
				return nil
			}
			if err := bufrw.Flush(); err != nil {
				JobCancel(fmt.Errorf("flush failed: %w", err))
				return nil
			}
			delete(pending, next)
			next++
			remaining--
			if remaining == 0 {
				fmt.Println("âœ… å…¨éƒ¨å‘é€å®Œæˆ")
				return writeChunkedEnd(bufrw)
			}
		}
	} // è¿™è¾¹çš„é€»è¾‘å¯ä»¥å°è¯•1ï¼Œå…¨æ”¾selectï¼›2ï¼Œä¸‹é¢éƒ¨åˆ†çš„DirectCtx.Done()æ”¾åœ¨å…¶ä»–selectï¼Ÿ
}

// ==========  Worker å‡½æ•°ï¼ˆå…³é”®ï¼‰ ==========
func chunkWorker(
	ctx context.Context,
	workerID int,
	targetURL string,
	taskCh <-chan ChunkTask,
	resultCh chan<- ChunkResult,
	headers http.Header,
	wg *sync.WaitGroup,
) {
	defer wg.Done()
	for {
		select {
		case <-ctx.Done():
			return
		case task := <-taskCh:
			if (task == ChunkTask{}) && len(taskCh) == 0 {
				return
			}
			data, err := downloadOneChunk(ctx, targetURL, task, headers)
			resultCh <- ChunkResult{Index: task.Index, Data: data, Err: err}
		}
	}
}

// DirectChunksWok ========== ä¸‹è½½å‰é¢éƒ¨åˆ†åˆ†å—ä¿è¯è¿æ¥é€šç•…æ€§ ==========
func DirectChunksWok(
	ctx context.Context,
	chunks []ChunkTask,
	bufrw *bufio.ReadWriter,
	targetURL string,
	Headers http.Header,
) {
	TaskNum := len(chunks)
	next := 0
	//fmt.Printf("TaskNum: %d\n", TaskNum)
	for {
		select {
		case <-ctx.Done():
			return
		default:
			if next >= TaskNum {
				return
			}
			task := chunks[next]

			NetCardClient.mu.RLock()
			IP := task.ClientIP
			ClientIndex := task.ClientIndex
			clientEntry := NetCardClient.Content[IP]
			if clientEntry == nil || len(clientEntry.CommonClient) <= ClientIndex || clientEntry.CommonClient[ClientIndex] == nil {
				NetCardClient.mu.RUnlock()
				fmt.Printf("Client for IP %s, Index %d does not exist.\n", IP, ClientIndex)
				return
			}
			client := clientEntry.CommonClient[ClientIndex]
			NetCardClient.mu.RUnlock()

			// è®¾ç½®å¯¹åº”Req
			req, err := http.NewRequestWithContext(ctx, http.MethodGet, targetURL, nil)
			if err != nil {
				return
			}
			// è®¾ç½®å¤´éƒ¨
			req.Header = Headers.Clone()
			req.Header = ReqH1ToH2Headers(req.Header)
			req.Header.Set("Range", fmt.Sprintf("bytes=%d-%d", task.Start, task.End))
			fmt.Printf("task: %+v\n", task)
			// å‘é€æŒ‡ä»¤
			resp, err := client.Do(req)
			if err != nil {
				fmt.Printf("client.Do error: %+v\n", err)
				return
			}
			// è®¾ç½®bufrw-Copy Writer
			monitorWriter := &MonitorWriterChunks{
				Writer:  bufrw,
				Monitor: NetCardBytes,
				LocalIP: IP,
				ctx:     ctx,
				Index:   ClientIndex,
			}
			// å‘é€å›å®¢æˆ·ç«¯
			actualSize := resp.ContentLength
			chunkSize := fmt.Sprintf("%x\r\n", actualSize)
			if _, err = bufrw.WriteString(chunkSize); err != nil {
				fmt.Printf("err1: %+v\n", err)
				resp.Body.Close()
				return
			}
			_, err = io.Copy(monitorWriter, resp.Body)
			if err != nil {
				fmt.Printf("err2: %+v\n", err)
				resp.Body.Close()
				return
			}
			resp.Body.Close()
			// å†™å…¥ç»“æŸæ ‡è®°
			if _, err = bufrw.WriteString("\r\n"); err != nil {
				fmt.Printf("err3: %+v\n", err)
				return
			}
			bufrw.Flush()
			next++
		}
	}
}

// ========== ä¸‹è½½å•ä¸ªåˆ†å—ï¼ˆä¿æŒä¸å˜ï¼‰ ==========
func downloadOneChunk(ctx context.Context, targetURL string, task ChunkTask, Headers http.Header) ([]byte, error) {

	// æš‚æ—¶è®¾ç½®ä¸ºå¯¹åº”probeClient
	IP := task.ClientIP
	ClientIndex := task.ClientIndex
	NetCardClient.mu.RLock()
	clientEntry := NetCardClient.Content[IP]
	if clientEntry == nil || len(clientEntry.CommonClient) <= ClientIndex || clientEntry.CommonClient[ClientIndex] == nil {
		NetCardClient.mu.RUnlock()
		return nil, fmt.Errorf("client for IP %s, Index %d does not exist", IP, ClientIndex)
	}
	client := clientEntry.CommonClient[ClientIndex]
	NetCardClient.mu.RUnlock()

	// åˆ›å»ºè¯·æ±‚
	req, err := http.NewRequestWithContext(ctx, http.MethodGet, targetURL, nil)
	if err != nil {
		return nil, fmt.Errorf("åˆ›å»ºè¯·æ±‚å¤±è´¥: %v", err)
	}

	// è®¾ç½®å¤´éƒ¨
	req.Header = Headers.Clone()
	req.Header = ReqH1ToH2Headers(req.Header)
	req.Header.Set("Range", fmt.Sprintf("bytes=%d-%d", task.Start, task.End))
	//fmt.Printf("task: %+v\n", task)

	resp, err := client.Do(req)
	if err != nil {
		return nil, err
	}
	defer resp.Body.Close()
	monitorReader := &MonitorReaderChunks{
		Reader:  resp.Body,
		Monitor: NetCardBytes,
		LocalIP: IP,
		ctx:     ctx,
		Index:   ClientIndex,
	}
	need := resp.ContentLength
	buf := make([]byte, need)
	n, err := io.ReadFull(monitorReader, buf)
	return buf[:n], err
}

// ========== 6. è¾…åŠ©å‡½æ•° ==========

func taskRetryable(err error) bool {
	return strings.HasPrefix(err.Error(), "retryable:")
}

func writeChunkedEnd(bufrw *bufio.ReadWriter) error {
	_, err := bufrw.WriteString("0\r\n\r\n")
	if err != nil {
		return err
	}
	return bufrw.Flush()
}

// ChunksDirectTaskGet ç”¨æ¥ä¿æŒå‰é¢éƒ¨åˆ†çš„æŒç»­æ€§ä¸‹è½½
func ChunksDirectTaskGet(AllChunksTasks []ChunkTask, SizeChunksDD int64) ([]ChunkTask, int, error) {
	var chunksDirect []ChunkTask
	var Add int64 = 0
	for _, chunkTask := range AllChunksTasks {
		chunksDirect = append(chunksDirect, chunkTask)
		Add += (chunkTask.End - chunkTask.Start) - 1
		if Add > SizeChunksDD {
			return chunksDirect, chunkTask.Index + 1, nil
		}
	}
	return nil, 0, fmt.Errorf("error on CHunksDirectTaskGet\n")
}
